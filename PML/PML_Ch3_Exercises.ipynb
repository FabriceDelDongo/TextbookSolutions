{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5d9e526-b938-4ad1-b442-4871a6065663",
   "metadata": {},
   "source": [
    "### Probabilistic Machine Learning (Book 1)\n",
    "\n",
    "Kevin P Murphy\n",
    "\n",
    "#### Exercises, Chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d740464f-37e6-4dfe-8022-68023a46060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4d37b1-b97f-47f6-9574-f27e9956d1f2",
   "metadata": {},
   "source": [
    "**Exercise 3.1** [Uncorrelated does not imply independent *]\n",
    "\n",
    "Let $X \\sim U(−1,1)$ and $Y = X^2$. \n",
    "\n",
    "Clearly $Y$ is dependent on $X$ (in fact, $Y$ is uniquely determined by $X$).\n",
    "\n",
    "However, show that $\\rho(X,Y ) = 0$. \n",
    "\n",
    "Hint: if $X \\sim U(a,b)$ then $E[X] = (a + b)/2$ and $V[X] = (b − a)^2/12$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e625ff-975b-41ac-8bea-f0ac25f54ef7",
   "metadata": {},
   "source": [
    "We know that\n",
    "\n",
    "$\\rho(X, Y) = \\frac{\\text{Cov}[X, Y]}{\\sqrt{V[X]V[Y]}}.$\n",
    "\n",
    "Since the denominator in the above consists of the product of square roots of two variances, which are greater than equal to zero by definition (with the equality holding only for a point mass), it suffices to show that the numerator is equal to zero.\n",
    "\n",
    "The covariance is defined as:\n",
    "\n",
    "$\\text{Cov}[X, Y] = E[(X - E[X])(Y - E[Y])].$\n",
    "\n",
    "We know from the hint, that\n",
    "\n",
    "$E[X] = (-1 + 1)/2 = 0,$ and\n",
    "\n",
    "$V[X] = (1 - (-1))^2/12 = 4/12 = 1/3.$\n",
    "\n",
    "We also have that\n",
    "\n",
    "$V[X] = E[(X-E[X])(X-E[X])] = E[X^2] - (E[X])^2 = E[X^2] = E[Y],$\n",
    "\n",
    "so that\n",
    "\n",
    "$\\text{Cov}[X, Y] = E[(X)(Y - V[X])] = E[XY - XV[X]] = E[XY] - E[XV[X]].$\n",
    "\n",
    "Since we know that $V[X] = 1/3,$ this becomes\n",
    "\n",
    "$\\text{Cov}[X, Y] = E[(X)(Y - V[X])] = E[XY - XV[X]] = E[XY] - \\frac{1}{3}E[X] = E[XY].$\n",
    "\n",
    "And\n",
    "\n",
    "$E[XY] = E[X^3] = 0,$\n",
    "\n",
    "since this is symmetric around 0, and hence $\\text{Cov}[X, Y] = 0$ and so $\\rho(X, Y) = 0.$\n",
    "\n",
    "We can see that this is true only for the case that $X$ is symmetric around $0$ by shifting the distribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8e8809-ba1e-40b1-a54d-4b0cae580db9",
   "metadata": {},
   "source": [
    "### Original Distribution\n",
    "\n",
    "$X \\sim U(−1,1)$ and $Y = X^2$\n",
    "\n",
    "Simulate 2,000 values of both $X$ and $Y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b2595f-1cd8-4e0b-b79a-ea389b367be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.random.uniform(-1, 1, size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81f3acbf-6699-4006-a4f7-bb9cc8a194ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ys = np.square(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f4732fe-46e5-4665-a8dd-de21fd141f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.15741458, 1.15088012, 0.865662  , 0.74557016, 0.80061226,\n",
       "        0.75557782, 0.76058164, 0.6404898 , 0.57043623, 0.56042858]),\n",
       " array([3.71839674e-07, 9.99238984e-02, 1.99847425e-01, 2.99770951e-01,\n",
       "        3.99694478e-01, 4.99618004e-01, 5.99541531e-01, 6.99465057e-01,\n",
       "        7.99388584e-01, 8.99312110e-01, 9.99235637e-01]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharey=True)\n",
    "ax[0].hist(Xs, density=True)\n",
    "ax[1].hist(Ys, density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87786fc5-c5d3-41ba-89c0-b41362f64e7f",
   "metadata": {},
   "source": [
    "These densitities look as expected.  What are the mean and variance in each case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "874cd3b4-15fe-4f05-b6ea-c8fb03a2840a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X has mean -0.02 and variance 0.35\n"
     ]
    }
   ],
   "source": [
    "print(f\"X has mean {Xs.mean():.2f} and variance {Xs.var():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e169e6-c1df-4fa0-abbe-cc96298c06e7",
   "metadata": {},
   "source": [
    "These are close to the analytical values of 0 and 1/3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8afa7e30-d0c4-47c7-8f95-d4b12b220dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y has mean 0.35 and variance 0.09\n"
     ]
    }
   ],
   "source": [
    "print(f\"Y has mean {Ys.mean():.2f} and variance {Ys.var():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b783fb-1d83-4a74-8afd-013c387e92f4",
   "metadata": {},
   "source": [
    "The expectation of $Y$ is equal to the variance of $X$.  This makes sense as:\n",
    "\n",
    "$E[Y] = E[X^2] = V[X] + (E[X])^2 = V[X] + 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e959f8f8-5958-4365-b9c5-8f663ec29d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34998283, -0.00509284],\n",
       "       [-0.00509284,  0.0931631 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(Xs, Ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc5d7d7-4b9e-4b05-8579-b59ba4417e99",
   "metadata": {},
   "source": [
    "The diagonal elements of the above matrix are the variances of $X$ and $Y$, and the off-diagonal elements are $\\sigma_1\\sigma_2 = \\sigma_2\\sigma_1.$\n",
    "\n",
    "We see that, as expected, these latter are $0$, so that the numerator of the ratio that defines the correlation is $0$, so we have $\\rho=0.$\n",
    "\n",
    "But what about the shifted case, where the expectation of the uniform distribution will _not_ be zero?\n",
    "\n",
    "### Shifted Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6782d329-5d56-442d-8752-76f6bf1838f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.random.uniform(9, 11, size=2000) # add 10 to the original distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e00dce4-4c80-40d1-8401-1f0f7f38c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ys = np.square(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e8351e9-208b-409c-b6d5-8ac8fb46d89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.02801929, 0.0287698 , 0.02576774, 0.02551756, 0.0233911 ,\n",
       "        0.02489213, 0.02839454, 0.02264058, 0.02189007, 0.02088938]),\n",
       " array([ 81.00015507,  84.99740186,  88.99464865,  92.99189544,\n",
       "         96.98914223, 100.98638902, 104.98363581, 108.9808826 ,\n",
       "        112.97812939, 116.97537618, 120.97262297]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharey=True)\n",
    "ax[0].hist(Xs, density=True)\n",
    "ax[1].hist(Ys, density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15642cd-10dd-4344-975b-893315e31058",
   "metadata": {},
   "source": [
    "Now both distributions look uniform in character.  What are the mean and variance in each case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3dd5d99c-f0ca-4a73-9ce9-102be43a06b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X has mean 9.99 and variance 0.33\n"
     ]
    }
   ],
   "source": [
    "print(f\"X has mean {Xs.mean():.2f} and variance {Xs.var():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d264c66-033d-4fc2-a975-dca8af9af844",
   "metadata": {},
   "source": [
    "These are close to the analytical values of $(9+11)/2 = 10$ and 1/3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37cd3009-1997-4768-9052-cfc140497014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y has mean 100.06 and variance 131.03\n"
     ]
    }
   ],
   "source": [
    "print(f\"Y has mean {Ys.mean():.2f} and variance {Ys.var():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d63cbdb-4e60-4ce2-ac9e-eeb55f190439",
   "metadata": {},
   "source": [
    "$Y$ now acts like a uniform distribution with parameters $9^2=81$ and $11^2=121,$ which would have expectation $(81+121)/2 = 101$ and variance $(121-81)^2/12$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3eac4d5-dc85-4aed-86ed-678526d39d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.32833397,   6.55852752],\n",
       "       [  6.55852752, 131.09479795]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(Xs, Ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30188c10-4ab7-4a46-a4ad-64cef75932e0",
   "metadata": {},
   "source": [
    "The off-diagonal elements of the covariance matrix are no longer 0, so the variables _are_ correlated in this case, with a correlation given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03070333-1b51-4900-b40f-a21da0cfee98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0001678888983798"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(Xs, Ys)[0, 1] / np.sqrt(Xs.var() * Ys.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6240012-42cb-4c50-8126-f58a0dca099c",
   "metadata": {},
   "source": [
    "I.e., they are linearly related to one another; it is only if the uniform distribution is symmetric around 0 that we see the zero correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c29aa5-6809-45fe-b43f-3688df5d7ffc",
   "metadata": {},
   "source": [
    "**Exercise 3.2** [Correlation coefficient is between -1 and +1]\n",
    "\n",
    "Prove that −1 ≤ ρ(X, Y ) ≤ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00539640-e56d-4ff9-ac2c-64afe620f3fd",
   "metadata": {},
   "source": [
    "We have that \n",
    "\n",
    "$\\rho(X, Y) = \\frac{\\text{Cov}[X, Y]}{\\sqrt{V[X]V[Y]}},$\n",
    "\n",
    "and we know that the denominator has a lower bound of $0.$\n",
    "\n",
    "We also know that if the two variables are perfectly uncorrelated (i.e., independent), then\n",
    "\n",
    "$\\text{Cov}[X, Y] = E[XY] - E[X]E[Y] = E[X]E[Y] - E[X]E[Y] = 0,$\n",
    "\n",
    "so $0$ provides a lower bound for $|\\text{Cov}[X, Y]|.$\n",
    "\n",
    "Considering the upper bound, the Cauchy-Schwarz inequality gives us that:\n",
    "\n",
    "$|\\langle \\mathbf{u}, \\mathbf{v} \\rangle| \\leq \\|\\mathbf{u}\\|\\|\\mathbf{v}\\|,$\n",
    "\n",
    "and\n",
    "\n",
    "$|\\langle \\mathbf{u}, \\mathbf{v} \\rangle|^2 \\leq \\langle \\mathbf{u}, \\mathbf{u} \\rangle \\cdot \\langle \\mathbf{v}, \\mathbf{v} \\rangle,$\n",
    "\n",
    "where $\\langle \\cdot , \\cdot \\rangle$ denotes the inner product, and $\\|\\cdot\\|$ the L2 norm.\n",
    "\n",
    "In our case, this can be expressed as\n",
    "\n",
    "$|\\langle \\mathbf{X} - E[\\mathbf{X}], \\mathbf{Y} - E[\\mathbf{Y}] \\rangle| \\leq \\|\\mathbf{X}-E[\\mathbf{X}]\\|\\|\\mathbf{Y}-E[\\mathbf{Y}]\\|,$\n",
    "\n",
    "or\n",
    "\n",
    "$|\\text{Cov}[X, Y]| \\leq \\sqrt{V[X]}\\sqrt{V[Y]},$\n",
    "\n",
    "where $\\text{Cov}[X, Y]$ is understood to be $E[\\langle X-E[X] , Y - E[Y] \\rangle],$ or the expectation of the inner product of each of $X$ and $Y$ less their respective means.\n",
    "\n",
    "This means that we also have:\n",
    "\n",
    "$|\\text{Cov}[X, Y]|^2 \\leq V[X]V[Y],$ so that\n",
    "\n",
    "$|\\rho(X, Y)| = \\left|\\frac{\\text{Cov}[X, Y]}{\\sqrt{V[X]V[Y]}}\\right| \\leq \n",
    "    \\frac{\\sqrt{V[X]V[Y]}}{\\sqrt{V[X]V[Y]}} = 1,$\n",
    "    \n",
    "so we know that \n",
    "\n",
    "$|\\rho(X, Y)| \\leq 1$ and therefore that\n",
    "\n",
    "$-1 \\leq \\rho(X, Y) \\leq 1.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9528c4-d083-4118-bf38-88eebc5af27c",
   "metadata": {},
   "source": [
    "**Exercise 3.3** [Correlation coefficient for linearly related variables is ±1 *]\n",
    "\n",
    "Show that, if $Y = aX +b$ for some parameters $a > 0$ and $b$, then $ρ(X,Y) = 1$. Similarly show that if $a < 0$, then $ρ(X, Y) = −1.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10258c-7962-4270-b4a4-c7b3afd83bc7",
   "metadata": {},
   "source": [
    "We have that\n",
    "\n",
    "$\\rho(X, Y) = \\frac{\\text{Cov}[X, Y]}{\\sqrt{V[X]V[Y]}},$\n",
    "\n",
    "and we know that, if $Y = aX +b,$ then $V[Y] = a^2V[X],$ so that\n",
    "\n",
    "$\\rho(X, aX+b) = \\frac{\\text{Cov}[X, aX+b]}{\\sqrt{a^2V[X]^2}}.$\n",
    "\n",
    "The covariance $\\text{Cov}[X, aX+b]$ is given by:\n",
    "\n",
    "$E[(X - E[X])(aX+b - E[aX + b])] = E[(X - E[X])(aX+b - E[aX] - b)] = E[(X - E[X])(aX - aE[X])]$\n",
    "\n",
    "$ = aE[X^2 - 2XE[X] + (E[X])^2] = a(E[X^2] - (E[X])^2) = aV[X].$\n",
    "\n",
    "Hence the correlation is given by\n",
    "\n",
    "$\\rho(X, aX+b) = \\frac{a}{\\sqrt{a^2}} \\frac{V[X]}{\\sqrt{V[X]^2}} = \\frac{a}{\\sqrt{a^2}}$ since the variance $V[X]$ is necessarily non-negative.\n",
    "\n",
    "This last quantity is equal to $+1$ for $a > 0$ and $-1$ for $a <0.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2d268-7fc7-462b-9d7e-ee2678d1ae56",
   "metadata": {},
   "source": [
    "**Exercise 3.4** [Linear combinations of random variables]\n",
    "\n",
    "Let $x$ be a random vector with mean $m$ and covariance matrix $\\Sigma$. Let $A$ and $B$ be matrices.\n",
    "\n",
    "a. Derive the covariance matrix of $Ax$. \n",
    "\n",
    "b. Show that $\\text{tr}(AB)$ = $\\text{tr}(BA)$.\n",
    "\n",
    "c. Derive an expression for $E[x^TAx]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef65e51-786b-4807-83f4-68d1b2d4b220",
   "metadata": {},
   "source": [
    "(a)\n",
    "\n",
    "The covariance matrix for $x$ is:\n",
    "\n",
    "$\\Sigma = \n",
    "\\begin{pmatrix}\n",
    "E[(x_1 - \\mu_1)(x_1 - \\mu_1)]     & E[(x_1 - \\mu_1)(x_2 - \\mu_2)]  & \\cdots & E[(x_1 - \\mu_1)(x_N - \\mu_N)]\\\\\n",
    "E[(x_2 - \\mu_2)(x_1 - \\mu_1)]     & E[(x_2 - \\mu_2)(x_2 - \\mu_2)]  & \\cdots & E[(x_2 - \\mu_2)(x_N - \\mu_N)]\\\\\n",
    "\\cdot &    &        & \\cdot \\\\\n",
    "\\cdot &    &        & \\cdot \\\\\n",
    "\\cdot &    &        & \\cdot \\\\\n",
    "E[(x_N - \\mu_N)(x_1 - \\mu_1)]     & E[(x_N - \\mu_N)(x_2 - \\mu_2)]  & \\cdots & E[(x_N - \\mu_N)(x_N - \\mu_N)]\\\\\n",
    "\\end{pmatrix},$\n",
    "\n",
    "where $x_i$ and $\\mu_i$ are the elements of $x$ and $\\mu$ respectively.  If $x$ has $N$ elements and matrix $A$ is $(M \\times N),$ then $Ax$ will have $M$ elements.\n",
    "\n",
    "The random vector $Ax$ and its mean vector will have elements\n",
    "\n",
    "$Ax = \\begin{pmatrix}\n",
    "\\sum_{i=1}^N A_{1i}x_i \\\\\n",
    "\\sum_{i=1}^N A_{2i}x_i \\\\\n",
    "\\sum_{i=1}^N A_{3i}x_i \\\\\n",
    "\\cdot \\\\\n",
    "\\cdot \\\\\n",
    "\\cdot \\\\\n",
    "\\sum_{i=1}^N A_{Mi}x_i \\\\\n",
    "\\end{pmatrix}\n",
    "$, $\\mu_{Ax} = \\begin{pmatrix}\n",
    "\\sum_{i=1}^N A_{1i}\\mu_i \\\\\n",
    "\\sum_{i=1}^N A_{2i}\\mu_i \\\\\n",
    "\\sum_{i=1}^N A_{3i}\\mu_i \\\\\n",
    "\\cdot \\\\\n",
    "\\cdot \\\\\n",
    "\\cdot \\\\\n",
    "\\sum_{i=1}^N A_{Mi}\\mu_i \\\\\n",
    "\\end{pmatrix},$\n",
    "\n",
    "respectively, leading to a covariance matrix:\n",
    "\n",
    "$\\Sigma_{Ax} = E\n",
    "\\begin{pmatrix}\n",
    "\\sum_{i=1}^N A_{1i}(x_i - \\mu_i)\\sum_{j=1}^N A_{1j}(x_j - \\mu_j) & \\sum_{i=1}^N A_{1i}(x_i - \\mu_i)\\sum_{j=1}^N A_{2j}(x_j - \\mu_j) & \\cdots & \\sum_{i=1}^N A_{1i}(x_i - \\mu_i)\\sum_{j=1}^N A_{Mj}(x_j - \\mu_j)\\\\\n",
    "\\sum_{i=1}^N A_{2i}(x_i - \\mu_i)\\sum_{j=1}^N A_{1j}(x_j - \\mu_j) & \\sum_{i=1}^N A_{2i}(x_i - \\mu_i)\\sum_{j=1}^N A_{2j}(x_j - \\mu_j) & \\cdots & \\sum_{i=1}^N A_{2i}(x_i - \\mu_i)\\sum_{j=1}^N A_{Mj}(x_j - \\mu_j)\\\\\n",
    "\\cdot &    &        & \\cdot \\\\\n",
    "\\cdot &    &        & \\cdot \\\\\n",
    "\\cdot &    &        & \\cdot \\\\\n",
    "\\sum_{i=1}^N A_{Mi}(x_i - \\mu_i)\\sum_{j=1}^N A_{1j}(x_j - \\mu_j) & \\sum_{i=1}^N A_{Mi}(x_i - \\mu_i)\\sum_{j=1}^N A_{2j}(x_j - \\mu_j) & \\cdots & \\sum_{i=1}^N A_{Mi}(x_i - \\mu_i)\\sum_{j=1}^N A_{Mj}(x_j - \\mu_j)\\\\\n",
    "\\end{pmatrix}$\n",
    "\n",
    "$= \n",
    "\\begin{pmatrix}\n",
    "\\sum_{i,j}^N A_{1i}A_{1j}\\Sigma_{ij} & \\sum_{i,j}^N A_{1i}A_{2j}\\Sigma_{ij} & \\cdots & \\sum_{i,j}^N A_{1i}A_{Mj}\\Sigma_{ij} \\\\\n",
    "\\sum_{i,j}^N A_{2i}A_{1j}\\Sigma_{ij} & \\sum_{i,j}^N A_{2i}A_{2j}\\Sigma_{ij} & \\cdots & \\sum_{i,j}^N A_{2i}A_{Mj}\\Sigma_{ij} \\\\\n",
    "\\cdot &    &        & \\cdot \\\\\n",
    "\\cdot &    &        & \\cdot \\\\\n",
    "\\cdot &    &        & \\cdot \\\\\n",
    "\\sum_{i,j}^N A_{Mi}A_{1j}\\Sigma_{ij} & \\sum_{i,j}^N A_{Mi}A_{2j}\\Sigma_{ij} & \\cdots & \\sum_{i,j}^N A_{Mi}A_{Mj}\\Sigma_{ij} \\\\\n",
    "\\end{pmatrix}.$\n",
    "\n",
    "Below we attempt to verify this by dummying up some numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "40c9dee1-24ff-4d61-acd7-bdfb0477eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original random vector x has size (3 x 1)\n",
    "m = np.array([5., 7., 9.])\n",
    "cov_half = np.array([[1, 1, 3],                   \n",
    "                [1, 4, 6], \n",
    "                [3, 6, 9]])\n",
    "cov = cov_half.T @ cov_half\n",
    "x_dist = multivariate_normal(mean=m, cov=cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "350fc6f1-9571-4c2c-8bb7-ed3f99db49c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11,  23,  36],\n",
       "       [ 23,  53,  81],\n",
       "       [ 36,  81, 126]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix for x\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1fda7c22-2aea-4a2c-b5b7-c4a4aba3504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix A has size (4 x 3)\n",
    "A = np.array([[1, 7, 3],\n",
    "              [4, 11, 4], \n",
    "              [5, 6, 7],\n",
    "              [2, 8, 5]])\n",
    "Ax_mean = A @ m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5749b091-37d0-45a3-996c-0ccfe94bee32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81., 133., 130., 111.])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ax_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "db4ff6ce-a8e6-4e34-876c-0bd32247b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov_pq(A, cov, p, q):\n",
    "    \"\"\"\n",
    "    get the p,q-th element of the covariance matrix for Ax,\n",
    "    where cov is the covariance matrix for rabdom vector x\n",
    "    \"\"\"\n",
    "    out = 0\n",
    "    N = A.shape[1]\n",
    "    for ii in range(N):\n",
    "        for ij in range(N):\n",
    "            out += A[p, ii] * A[q, ij] * cov[ii, ij]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "415313ef-a9ba-4839-939a-e02bd899eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = A.shape[0]\n",
    "cov_Ax = np.zeros((M, M))\n",
    "for pp in range(M):\n",
    "    for pq in range(M):\n",
    "        cov_Ax[pp, pq] = get_cov_pq(A, cov, pp, pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c373b0cf-bd69-4d57-9642-4e7125f40f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7682., 12051., 12089., 10561.],\n",
       "       [12051., 18909., 18972., 16569.],\n",
       "       [12089., 18972., 19061., 16630.],\n",
       "       [10561., 16569., 16630., 14522.]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_Ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a94a9ebd-6d48-4377-9b6f-3b9bfb1fd167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n.b., the covariance matrix is rejected as a singular matrix.\n",
    "#Ax_dist = multivariate_normal(mean=Ax_mean, cov=cov_Ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f7016fce-6576-43bc-a875-ab0fd625f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we try with a square matrix?\n",
    "B = np.array([[5, 6, 7], [1.1, 1.2, 1.3], [5.5, 5.6, 5.7]])\n",
    "cov_Bx = np.zeros((3, 3))\n",
    "for pp in range(3):\n",
    "    for pq in range(3):\n",
    "        cov_Bx[pp, pq] = get_cov_pq(B, cov, pp, pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ca0e69e8-86c3-4a6d-b3d8-6f54a73eaad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.10e+10, -8.06e+11,  9.68e+10],\n",
       "       [-8.06e+11,  9.16e+12, -1.10e+12],\n",
       "       [ 9.68e+10, -1.10e+12,  1.32e+11]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in this case we do not get a singular matrix?  Possibly it is necessary to use a square matrix (which \n",
    "# consequently must be of the same size as the original random vector) to avoid singular matrices\n",
    "np.linalg.inv(cov_Bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a0d28930-23c1-4de3-9b12-92981476866e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09, -0.14, -0.03,  0.13],\n",
       "       [-0.14,  0.28,  0.  , -0.22],\n",
       "       [-0.03,  0.  ,  0.04, -0.02],\n",
       "       [ 0.13, -0.22, -0.02,  0.19]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can still find the \"pseudo-inverse\"\n",
    "np.linalg.pinv(cov_Ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d0e273bc-5430-45da-be38-dd217396a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also create a distribution with the pseudo-inverse\n",
    "Ax_dist = multivariate_normal(mean=Ax_mean, cov=cov_Ax, allow_singular=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83d73d-7800-4454-8789-9ce7df3598bc",
   "metadata": {},
   "source": [
    "The matrix produced in this way is supposedly singular.  Let's get an estimate of the covariance matrix produced using random variables drawn from vector Ax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ced4fe6b-8567-40f8-8dae-6a1dbe9515c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs = x_dist.rvs(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7a891fc5-62b2-4b00-959b-7578df4bb8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "61665d15-7efa-428e-9c3e-801d5877cd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "86898f7b-c9bb-42fe-b0f0-35d8dc02262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate transformed rvs by multiplying by A\n",
    "Ax_rvs = (rvs @ A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5e3cf688-d5e8-422f-9bd4-5777a51052a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 82.40621043, 135.17988356, 132.14390781, 112.91609514])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ax_rvs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e6a423c2-4276-4b0f-9bad-371a222f74e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy estimate:\n",
      "[[ 7647.82 11998.25 12025.1  10510.57]\n",
      " [11998.25 18827.57 18873.3  16491.15]\n",
      " [12025.1  18873.3  18945.76 16537.1 ]\n",
      " [10510.57 16491.15 16537.1  14448.05]]\n",
      "Computed analytically:\n",
      "[[ 7682. 12051. 12089. 10561.]\n",
      " [12051. 18909. 18972. 16569.]\n",
      " [12089. 18972. 19061. 16630.]\n",
      " [10561. 16569. 16630. 14522.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "print(\"Numpy estimate:\")\n",
    "print(np.cov(Ax_rvs.T))\n",
    "print(\"Computed analytically:\")\n",
    "print(cov_Ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8741a5-d769-4243-a4e4-30cfd5f558df",
   "metadata": {},
   "source": [
    "The above are close enough that it appears that the elements of the covariance matrix are being calculated correctly, even though numpy complains that the resulting matrix is singular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ced6b9bd-b69f-4a5f-8179-d9c68e2cd73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ax_rvs_pinv = Ax_dist.rvs(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8322b7a7-151d-4078-8420-5b07fd224d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7473.28, 11719.63, 11747.19, 10270.53],\n",
       "       [11719.63, 18383.06, 18429.64, 16107.9 ],\n",
       "       [11747.19, 18429.64, 18502.18, 16154.55],\n",
       "       [10270.53, 16107.9 , 16154.55, 14117.81]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(Ax_rvs_pinv.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8eb3c-8e0f-42ae-b5a1-87df2aba3c10",
   "metadata": {},
   "source": [
    "We see that the random variables produced by the elements of $Ax$ are similar, whether we use the computed covariance matrix (allowing for the fact that we need the pseudo-inverse) or we multiply random variables produced by $x$ by matrix $A$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "26ec17ba-6c7e-41c8-929e-f61a55f8bece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.41e-05, 6.03e-05, 1.57e-04, 2.77e-04, 7.36e-04, 1.22e-03,\n",
       "        1.68e-03, 2.81e-03, 3.34e-03, 3.17e-03, 3.09e-03, 2.54e-03,\n",
       "        2.06e-03, 1.36e-03, 9.41e-04, 4.22e-04, 1.33e-04, 4.82e-05,\n",
       "        2.41e-05, 2.41e-05]),\n",
       " array([-284.82, -243.36, -201.9 , -160.45, -118.99,  -77.54,  -36.08,\n",
       "           5.38,   46.83,   88.29,  129.75,  171.2 ,  212.66,  254.11,\n",
       "         295.57,  337.03,  378.48,  419.94,  461.4 ,  502.85,  544.31]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "\n",
    "ax[0, 0].hist(Ax_rvs[:, 0], density=True, bins=20)\n",
    "ax[0, 0].hist(Ax_rvs_pinv[:, 0], density=True, bins=20)\n",
    "\n",
    "ax[0, 1].hist(Ax_rvs[:, 1], density=True, bins=20)\n",
    "ax[0, 1].hist(Ax_rvs_pinv[:, 1], density=True, bins=20)\n",
    "\n",
    "ax[1, 0].hist(Ax_rvs[:, 2], density=True, bins=20)\n",
    "ax[1, 0].hist(Ax_rvs_pinv[:, 2], density=True, bins=20)\n",
    "\n",
    "ax[1, 1].hist(Ax_rvs[:, 3], density=True, bins=20)\n",
    "ax[1, 1].hist(Ax_rvs_pinv[:, 3], density=True, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43547ac-56d9-463c-b4c0-367dd91d1912",
   "metadata": {},
   "source": [
    "(b)\n",
    "\n",
    "$A$ and $B$ must be square matrices for their traces to be defined, hence $A$ and $B$ must be of the same size, say $M$.\n",
    "\n",
    "The diagonal elements of $AB$ will be equal to the diagonal elements of $BA$:\n",
    "\n",
    "$(AB)_{ii} = (BA)_{ii}$\n",
    "\n",
    "where $1 \\leq i \\leq M$.  Since $\\text{tr}(A)$ is simply the sum of the diagonal elements, we must have $\\text{tr}(AB) = \\text{tr}(BA).$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c294e3-fd7b-4c9c-ac87-f59770fd62d4",
   "metadata": {},
   "source": [
    "(c)\n",
    "\n",
    "For $x^TAx$ to be defined, $A$ must be a square matrix with the same size as $x$ ($M = N$).  In that case,\n",
    "\n",
    "$x^tAx = \\begin{pmatrix}\n",
    "x_1 & x_2 & x_3 & \\cdots & x_N\n",
    "\\end{pmatrix}\n",
    "\\cdot\n",
    "\\begin{pmatrix}\n",
    "\\sum_{i=1}^N A_{1i}x_i \\\\\n",
    "\\sum_{i=1}^N A_{2i}x_i \\\\\n",
    "\\sum_{i=1}^N A_{3i}x_i \\\\\n",
    "\\cdot \\\\\n",
    "\\cdot \\\\\n",
    "\\cdot \\\\\n",
    "\\sum_{i=1}^N A_{Ni}x_i \\\\\n",
    "\\end{pmatrix}$\n",
    "\n",
    "$=\\sum_{i,j}^N A_{ji} x_jx_i.$  The expectation $E[x^TAx]$ must then be\n",
    "\n",
    "$E[x^TAx] = E[\\sum_{i,j}^N A_{ji} x_jx_i] = \\sum_{i,j}^N A_{ji}E[x_jx_i].$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eef873-a60f-4ebc-8830-efcc96dcf56a",
   "metadata": {},
   "source": [
    "**Exercise 3.7** [Sensor fusion with known variances in 1d]\n",
    "\n",
    "Suppose we have two sensors with known (and different) variances $v_1$ and $v_2$, but unknown (and the same)\n",
    "mean $\\mu$. Suppose we observe $n_1$ observations $y_i^{(1)} \\sim N(\\mu,v_1)$ from the first sensor and $n_2$ observations $y_i^{(2)} \\sim N(\\mu,v_2)$ from the second sensor. (For example, suppose $\\mu$ is the true temperature outside, and sensor $1$ is a precise (low variance) digital thermosensing device, and sensor $2$ is an imprecise (high variance) mercury thermometer.) Let $D$ represent all the data from both sensors. What is the posterior $p(\\mu|D)$, assuming a non-informative prior for $\\mu$ (which we can simulate using a Gaussian with a precision of $0$)? Give an explicit expression for the posterior mean and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a72a486-1fea-47c5-90a5-3bd866f75ca5",
   "metadata": {},
   "source": [
    "We can set this up as a linear Gaussian system:\n",
    "\n",
    "$p(\\mu) = \\mathcal{N}(\\mu|\\mu_0, \\Sigma_\\mu)$ (for the non-informative prior we can set $\\frac{1}{\\Sigma_\\mu}=0$),\n",
    "\n",
    "$p(y^{(1)}|\\mu) = \\mathcal{N}(y^{(1)}|W_1\\mu, \\Sigma_1),$\n",
    "\n",
    "$p(y^{(2)}|\\mu) = \\mathcal{N}(y^{(2)}|W_2\\mu, \\Sigma_2),$\n",
    "\n",
    "where $W_1$ is a $n_1 \\times 1$ column (n.b., KPM has this as row) vector of $1$s and $W_2$ is a $n_2 \\times 1$ column (KPM has row) vector of $1$s; $\\Sigma_1$ and $\\Sigma_2$ are diagonal square matrices of side $n_1$ and $n_2$ respectively, whose diagonal elements are the known quantities $v_1$ and $v_2$, respectively.\n",
    "\n",
    "$y^{(1)}$ and $y^{(2)}$ can be combined into a single system:\n",
    "\n",
    "$y = \\begin{pmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\end{pmatrix},$\n",
    "\n",
    "where the mean vector $\\mu$, ($(n_1 + n_2) \\times 1)$ weight (column, n.b., KPM has this as row) vector $W$ and $((n_1 + n_2) \\times (n_1 + n_2))$ variance matrix $\\Sigma_y$ can be easily constructed by concatenating the corresponding quantities from the separate systems.\n",
    "\n",
    "We can then apply Bayes' rule for Gaussians to find the posterior precision:\n",
    "\n",
    "$\\Sigma_{\\mu|y}^{-1} = \\Sigma_\\mu^{-1} + W^T\\Sigma_y^{-1}W,$\n",
    "\n",
    "so that \n",
    "\n",
    "$\\Sigma_{\\mu|y}^{-1} = W^T\\Sigma_y^{-1}W = \\frac{n_1}{v_1} + \\frac{n_2}{v_2},$\n",
    "\n",
    "since the prior precision $\\Sigma_\\mu^{-1} = 0$.\n",
    "\n",
    "The posterior mean will then be given by:\n",
    "\n",
    "$\\mu_{\\mu|y} = \\Sigma_{\\mu|y}[W^T\\Sigma_{y}^{-1}(y-b) + \\Sigma_\\mu^{-1}\\mu_0]$\n",
    "\n",
    "$= \\left[\\frac{n_1}{v_1} + \\frac{n_2}{v_2}\\right]^{-1}\\left (\\sum_{i=1}^{n_1}y_i/v_1 + \\sum_{i=n_1+1}^{n_1+n_2}y_i/v_2 \\right)\n",
    "= \\left[\\frac{n_1}{v_1} + \\frac{n_2}{v_2}\\right]^{-1} \\left( \\frac{n_1\\bar{y}_1}{v_1} + \\frac{n_2\\bar{y}_2}{v_2} \\right).$ \n",
    "\n",
    "We can simplify the system using the sample means of $y_1$ and $y_2$ so that \n",
    "\n",
    "$y = \\begin{pmatrix}\n",
    "\\bar{y}_1 \\\\\n",
    "\\bar{y}_2 \\\\\n",
    "\\end{pmatrix},$\n",
    "\n",
    "with $W$ as before, and $\\Sigma_y$ now a $2 \\times 1$ column vector with elements $v_1/n_1$ and $v_2/n_2.$\n",
    "\n",
    "With the noninformative prior, the Bayes rule for Gaussians will leads to the same posterior mean and variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a49497da-9ed4-4bd4-a0d4-1c43ce9980ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set μ, v1, v2\n",
    "μ = 15.\n",
    "v1 = 1.0 # lower variance / higher precision\n",
    "v2 = 3.0 # higher variance / lower precision\n",
    "\n",
    "# say we have 20 observations from the high precision sensor\n",
    "# and 60 observations from the low precision sensor\n",
    "n1 = 20; n2 = 60\n",
    "y1 = np.random.normal(μ, v1, size=n1)\n",
    "y2 = np.random.normal(μ, v2, size=n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "59860509-9b48-43fe-8573-36be99929c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W is a column vector with shape: (80, 1)\n",
      "Σ_y is a diagonal matrix with shape: (80, 80)\n",
      "\n",
      "Posterior variance via matrix multiplication: 0.025\n",
      "1/((n1/v1) + (n2/v2)): 0.025\n",
      "\n",
      "Posterior mean via matrix multiplication: 14.9393\n",
      "1/((n1/v1) + (n2/v2)) * (n1 * y1.mean()/v1 + n2 * y2.mean()/v2):     14.9393\n"
     ]
    }
   ],
   "source": [
    "# the combined y is the concatenation of y1, y2\n",
    "y = np.concatenate([y1, y2], axis=0)\n",
    "\n",
    "# the individual weights are column vectors\n",
    "W1 = np.ones(n1).reshape(n1, 1)\n",
    "W2 = np.ones(n2).reshape(n2, 1)\n",
    "\n",
    "# the individual variance matrices are diagonal\n",
    "Σ_y1 = v1 * np.eye(n1)\n",
    "Σ_y2 = v2 * np.eye(n2)\n",
    "\n",
    "# the combined system consists of concatenations of these:\n",
    "W = np.concatenate([W1, W2], axis=0)\n",
    "print(f\"W is a column vector with shape: {W.shape}\")\n",
    "Σ_y = np.vstack([np.hstack([Σ_y1, np.zeros((20, 60))]),\n",
    "                 np.hstack([np.zeros((60, 20)), Σ_y2])])\n",
    "print(f\"Σ_y is a diagonal matrix with shape: {Σ_y.shape}\")\n",
    "print()\n",
    "postvar = np.linalg.inv(W.T @ np.linalg.inv(Σ_y) @ W)\n",
    "print(f\"Posterior variance via matrix multiplication: {postvar.squeeze()}\")\n",
    "print(f\"1/((n1/v1) + (n2/v2)): {1/((n1/v1) + (n2/v2))}\")\n",
    "print()\n",
    "postmean = postvar @ W.T @ np.linalg.inv(Σ_y) @ y\n",
    "print(f\"Posterior mean via matrix multiplication: {postmean.squeeze():.4f}\")\n",
    "print(f\"1/((n1/v1) + (n2/v2)) * (n1 * y1.mean()/v1 + n2 * y2.mean()/v2): \\\n",
    "    {1/((n1/v1) + (n2/v2)) * (n1 * y1.mean()/v1 + n2 * y2.mean()/v2):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88460545-e814-4080-8853-67483ba2ebaf",
   "metadata": {},
   "source": [
    "**Exercise 3.8** [Show that the Student distribution can be written as a Gaussian scale mixture]\n",
    "\n",
    "Show that a Student distribution can be written as a Gaussian scale mixture, where we use a Gamma\n",
    "mixing distribution on the precision α, i.e.\n",
    "\n",
    "$p(x|\\mu, a, b) = \\int_{0}^{\\infty} \\mathcal{N}(x|\\mu, \\alpha^{-1})\\text{Ga}(\\alpha, a, b)d\\alpha$\n",
    "\n",
    "This can be viewed as an infinite mixture of Gaussians, with different precisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3fa317-a74b-4801-8005-e5514410528a",
   "metadata": {},
   "source": [
    "$\\mathcal{N}(x|\\mu, \\alpha^{-1}) = \\frac{\\alpha^{1/2}}{\\sqrt{2\\pi}}\\exp\\left\\{-\\frac{\\alpha}{2} (x-\\mu)^2 \\right\\}$\n",
    "\n",
    "$\\text{Ga}(\\alpha, a, b) = \\frac{b^a}{\\Gamma(a)}\\alpha^{a-1}\\exp\\{-b\\alpha\\}$\n",
    "\n",
    "$\\implies \\int_{0}^{\\infty} \\mathcal{N}(x|\\mu, \\alpha^{-1})\\text{Ga}(\\alpha, a, b)d\\alpha \n",
    "= \\int_{0}^{\\infty} \\frac{\\alpha^{a-1/2}}{\\sqrt{2\\pi}b^a\\Gamma(a)}\\exp\\left\\{-\\alpha \\left [\\frac{(x-\\mu)^2}{2} + \\frac{1}{b}\\right] \\right\\}  d\\alpha$\n",
    "\n",
    "$= \\frac{1}{\\sqrt{2\\pi}b^a\\Gamma(a)} \\int_{0}^{\\infty} \\alpha^{\\kappa_1-1} \\exp\\left\\{ \\alpha / \\kappa_2 \\right\\}  d\\alpha,$\n",
    "\n",
    "where\n",
    "\n",
    "$\\kappa_1 = a+1/2,$ and $\\kappa_2 = \\left[ \\frac{(x-\\mu)^2}{2} + \\frac{1}{b} \\right]^{-1}.$\n",
    "\n",
    "This means that\n",
    "\n",
    "$\\int_{0}^{\\infty} \\mathcal{N}(x|\\mu, \\alpha^{-1})\\text{Ga}(\\alpha, a, b)d\\alpha\n",
    " = \\frac{1}{\\sqrt{2\\pi}b^a\\Gamma(a)} \\frac{\\Gamma(\\kappa_1)}{\\kappa_2^{\\kappa_1}} \\int_{0}^{\\infty} \\text{Ga}(\\alpha|\\kappa_1, \\kappa_2) d\\alpha,$\n",
    " \n",
    "and since the integral over a Gamma distribution from $0$ to infinity is equal to one, we have:\n",
    "\n",
    "$\\int_{0}^{\\infty} \\mathcal{N}(x|\\mu, \\alpha^{-1})\\text{Ga}(\\alpha, a, b)d\\alpha\n",
    " = \\frac{1}{\\sqrt(2\\pi)b^a\\Gamma(a)} \\frac{\\Gamma(a+1/2)}{\\left[ \\frac{(x-\\mu)^2}{2} + \\frac{1}{b} \\right]^{a+1/2}}\n",
    "= \\frac{\\sqrt{b}}{\\sqrt(2\\pi)}\\frac{\\Gamma(a+1/2)}{\\Gamma(a)}\\left[ \\frac{b(x-\\mu)^2}{2} + 1 \\right]^{-(a+1/2)}.$\n",
    "\n",
    "The Student-$t$ distribuution has the form:\n",
    "\n",
    "$t_{\\nu}(x|\\mu, \\sigma^2) = \\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\Gamma(\\frac{\\nu}{2})\\sqrt{\\nu\\pi}\\sigma}\\left[ 1 + \\frac{1}{\\nu}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2 \\right]^{-\\frac{\\nu+1}{2}}.$\n",
    "\n",
    "So, with \n",
    "\n",
    "$a = \\nu / 2 \\Leftrightarrow \\nu = 2a,$\n",
    "\n",
    "and\n",
    "\n",
    "$b = \\frac{2}{\\nu \\sigma^2} \\Leftrightarrow \\sigma^2 = \\frac{2}{\\nu b},$\n",
    "\n",
    "we can write\n",
    "\n",
    "$t_{2a}(x|\\mu, \\frac{2}{\\nu b}) = \\frac{\\Gamma(a+1/2)}{\\Gamma(a)} \\frac{1}{\\sqrt{\\nu\\pi}} \\sqrt{\\frac{\\nu b}{2}} \\left[ 1 + \\frac{b \\sigma^2}{2}\\left( \\frac{x-\\mu}{\\sigma}\\right)^2 \\right]^{-(a+1/2)}\n",
    "= \\frac{\\Gamma(a+1/2)}{\\Gamma(a)} \\sqrt{\\frac{b}{2\\pi}} \\left[ 1 + \\frac{b}{2}\\left( x-\\mu\\right)^2 \\right]^{-(a+1/2)}\n",
    "= \\int_{0}^{\\infty} \\mathcal{N}(x|\\mu, \\alpha^{-1})\\text{Ga}(\\alpha, a, b)d\\alpha.$\n",
    "\n",
    "We can therefore consider the $t$-distribution to be a scale mix of Gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843eee8-8bc9-4c06-93c5-c646f53d7db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
